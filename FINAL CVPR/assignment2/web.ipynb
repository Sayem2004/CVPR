{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b541ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SYSTEM CHECK ---\n",
      "âœ… Labels Loaded: ['21-45902-3' '22-46138-1' '22-46139-1' '22-46141-1' '22-46156-1'\n",
      " '22-46258-1' '22-46275-1' '22-46293-1' '22-46342-1' '22-46473-1'\n",
      " '22-46536-1' '22-46666-1' '22-46677-1' '22-46679-1' '22-46840-1'\n",
      " '22-46857-1' '22-46877-1' '22-46880-1' '22-46887-1' '22-46931-1'\n",
      " '22-46945-1' '22-46983-1' '22-47027-1' '22-47180-1 ' '22-47294-1'\n",
      " '22-47384-2' '22-47402-2' '22-47802-2' '22-47813-2' '22-47884-2'\n",
      " '22-47888-2' '22-47892-2' '22-47894-2' '22-47898-2' '22-47925-2'\n",
      " '22-47934-2' '22-47966-2' '22-47968-2' '22-48005-2' '22-48021-2'\n",
      " '22-48023-2 ' '22-48039-2' '22-48055-2' '22-48064-2' '22-48091-2'\n",
      " '22-48133-2 ' '22-48205-2' '22-48434-3' '22-48541-3' '22-48569-3'\n",
      " '22-48582-3' '22-48833-3' '22-49037-3' '22-49167-3' '22-49196-3'\n",
      " '22-49338-3' '22-49355-3' '22-49370-3' '22-49421-3' '22-49450-3'\n",
      " '22-49451-3' '22-49453-3' '22-49507-3' '22-49575-3' '22-49609-3'\n",
      " '22-49619-3' '22-49621-3' '22-49643-3' '22-49644-3' '22-49745-3'\n",
      " '22-49783-3' '22-49791-3' '22-49800-3' '22-49824-3' '22-49843-3'\n",
      " '22-49852-3' '22-49861-3' '22-49862-3' '23-50066-1' '23-50158-1'\n",
      " '23-50254-1' '23-50277-1' '23-50279-1' '23-50346-1' '23-50689-1'\n",
      " '23-51127-1' '23-51308-1' '23-53577-3'] (Total: 88)\n",
      "ðŸ”¨ Reconstructing Model Architecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:463: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Weights Loaded Successfully.\n",
      "\n",
      "ðŸš€ SYSTEM READY. PRESS 'q' TO QUIT.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"friend_face_model.h5\"\n",
    "LABEL_PATH = \"friend_labels.pkl\"  \n",
    "IMG_SIZE = 160\n",
    "THRESHOLD = 0.60\n",
    "NUM_CLASSES = 0 \n",
    "\n",
    "\n",
    "print(\"--- SYSTEM CHECK ---\")\n",
    "if not os.path.exists(MODEL_PATH) or not os.path.exists(LABEL_PATH):\n",
    "    print(\"ERROR: Files missing.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    with open(LABEL_PATH, \"rb\") as f:\n",
    "        le = pickle.load(f)\n",
    "    class_names = le.classes_\n",
    "    NUM_CLASSES = len(class_names)\n",
    "    print(f\" Labels Loaded: {class_names} (Total: {NUM_CLASSES})\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading labels: {e}\")\n",
    "    print(\" pip install scikit-learn\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(\"Reconstructing Model Architecture\")\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    base = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights=None \n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs * 255.0)\n",
    "    x = base(x, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "try:\n",
    "\n",
    "    model = build_model()\n",
    "    \n",
    "   \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print(\"Model Weights Loaded Successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Failed to load weights: {e}\")\n",
    "    print(\"Make sure NUM_CLASSES matches exactly what was trained!\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "xml_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(xml_path)\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(\" Face Detector XML not found.\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\" Webcam not found.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n SYSTEM READY. PRESS 'q' TO QUIT.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(60, 60))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw Box\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        try:\n",
    "            # Prepare Face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            # Normalize (0-1)\n",
    "            normalized = resized.astype(np.float32) / 255.0\n",
    "            input_data = np.expand_dims(normalized, axis=0)\n",
    "            \n",
    "            # Predict\n",
    "            preds = model.predict(input_data, verbose=0)\n",
    "            idx = np.argmax(preds)\n",
    "            conf = np.max(preds)\n",
    "            \n",
    "            # Show Result\n",
    "            if conf > THRESHOLD:\n",
    "                name = class_names[idx]\n",
    "                color = (0, 255, 0)\n",
    "                text = f\"{name} ({int(conf*100)}%)\"\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                text = f\"Unknown ({int(conf*100)}%)\"\n",
    "            \n",
    "            cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass # Skip bad frames\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
